{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e41d19-3a35-45cb-980c-cc0713b7dbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries/packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3889e70c-419c-4318-a361-ea3129743d16",
   "metadata": {},
   "source": [
    "User guide notes about data format\n",
    "(provided with dataset download):\n",
    "-----------------------------------\n",
    "\"Line 1…6 are useless in this dataset, and can be ignored. Points are described in following lines, one for each line.\n",
    "\n",
    "- Field 1: Latitude in decimal degrees.\n",
    "- Field 2: Longitude in decimal degrees.\n",
    "- Field 3: All set to 0 for this dataset.\n",
    "- Field 4: Altitude in feet (-777 if not valid).\n",
    "- Field 5: Date - number of days (with fractional part) that have passed since 12/30/1899.\n",
    "- Field 6: Date as a string.\n",
    "- Field 7: Time as a string.\n",
    "\n",
    "Note that field 5 and field 6&7 represent the same date/time in this dataset. You may use either of them.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f618452-93e9-456a-a96b-5ac405a27162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for loading specific invidual PLT file given file_path\n",
    "def load_plt_file(file_path):\n",
    "\n",
    "    # load file as df while skipping first six rows (unneeded header info)\n",
    "    plt_df = pd.read_csv(file_path, skiprows = 6, header = None)\n",
    "\n",
    "    # assign columns\n",
    "    plt_df.columns = [\n",
    "        'latitude',\n",
    "        'longitude', \n",
    "        'zero_field',\n",
    "        'altitude_ft',\n",
    "        'date_days',\n",
    "        'date_string',\n",
    "        'time_string'\n",
    "    ]\n",
    "\n",
    "    return plt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c97d9c8-3239-403a-9245-666f50deec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for adding plt data to existing df\n",
    "def add_plt_data(df, file_path):\n",
    "\n",
    "    # use load_plt_file on given file and extract data\n",
    "    plt_df = load_plt_file(file_path)\n",
    "\n",
    "    # add plt data to existing dataframe\n",
    "    res_df = pd.concat([df, plt_df], axis = 0)\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e913ae4a-f776-42a1-88e7-519de8519885",
   "metadata": {},
   "source": [
    "Filtering through all the folders and keeping track of the ones that have a 'labels.txt' file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e7763ca-f709-428c-8ed3-d3748ca4e877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['010',\n",
       " '020',\n",
       " '021',\n",
       " '052',\n",
       " '053',\n",
       " '056',\n",
       " '058',\n",
       " '059',\n",
       " '060',\n",
       " '062',\n",
       " '064',\n",
       " '065',\n",
       " '067',\n",
       " '068',\n",
       " '069',\n",
       " '073',\n",
       " '075',\n",
       " '076',\n",
       " '078',\n",
       " '080',\n",
       " '081',\n",
       " '082',\n",
       " '084',\n",
       " '085',\n",
       " '086',\n",
       " '087',\n",
       " '088',\n",
       " '089',\n",
       " '091',\n",
       " '092',\n",
       " '096',\n",
       " '097',\n",
       " '098',\n",
       " '100',\n",
       " '101',\n",
       " '102',\n",
       " '104',\n",
       " '105',\n",
       " '106',\n",
       " '107',\n",
       " '108',\n",
       " '110',\n",
       " '111',\n",
       " '112',\n",
       " '114',\n",
       " '115',\n",
       " '116',\n",
       " '117',\n",
       " '118',\n",
       " '124',\n",
       " '125',\n",
       " '126',\n",
       " '128',\n",
       " '129',\n",
       " '136',\n",
       " '138',\n",
       " '139',\n",
       " '141',\n",
       " '144',\n",
       " '147',\n",
       " '153',\n",
       " '154',\n",
       " '161',\n",
       " '163',\n",
       " '167',\n",
       " '170',\n",
       " '174',\n",
       " '175',\n",
       " '179']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define base directory holding the geolife data\n",
    "geolife_dir = \"../Data/GeoLife_Data\"\n",
    "\n",
    "# get all user folders within geolife directory\n",
    "user_folders = [f for f in os.listdir(geolife_dir)\n",
    "                if os.path.isdir(os.path.join(geolife_dir, f))\n",
    "                and f.isdigit()]\n",
    "\n",
    "# filter through the folders and check for labels.txt\n",
    "folders_with_labels = []\n",
    "for folder in user_folders:\n",
    "    labels_path = os.path.join(geolife_dir, folder, \"labels.txt\")\n",
    "    if os.path.exists(labels_path):\n",
    "        folders_with_labels.append(folder)\n",
    "\n",
    "folders_with_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a76f602-4a1f-42cb-9b32-afe821e4ff7a",
   "metadata": {},
   "source": [
    "For reference, the below is the information included in the user guide that regards the mode transportation labels.\n",
    "--------------------------\n",
    "\"73 users have labeled their trajectories with transportation mode, such as driving, taking a bus, riding a bike and walking. There\n",
    "is a label file storing the transportation mode labels in each user’s folder. See section 4.2 for the format of labels.\n",
    "The total distance and duration of transportation modes are listed in Figure 6. Though this only covers a part of the dataset used\n",
    "in the following papers, the scale of this released dataset can still support transportation mode learning.\"\n",
    "\n",
    "Figure 6 Total distance and duration of transportation modes:\n",
    "| Transportation Mode | Distance (km) | Duration (hour) |\n",
    "| :------------------ | ------------: | --------------: |\n",
    "| Walk                |        10,123 |           5,460 |\n",
    "| Bike                |         6,495 |           2,410 |\n",
    "| Bus                 |        20,281 |           1,507 |\n",
    "| Car & taxi          |        32,866 |           2,384 |\n",
    "| Train               |        36,253 |             745 |\n",
    "| Airplane            |        24,789 |              40 |\n",
    "| Other               |         9,493 |             404 |\n",
    "| **Total**           |    **140,304**|       **12,953** |\n",
    "\n",
    "--------------------------\n",
    "\n",
    "\"Possible transportation modes are: walk, bike, bus, car, subway, train, airplane, boat, run and motorcycle. Again, we have\n",
    "converted the date/time of all labels to GMT, even though most of them were created in China.\n",
    "\n",
    "Example:\n",
    "| Start Time          | End Time            | Transportation Mode |\n",
    "| :------------------ | :------------------ | :------------------ |\n",
    "| 2008/04/02 11:24:21 | 2008/04/02 11:50:45 | bus                 |\n",
    "| 2008/04/03 01:07:03 | 2008/04/03 11:31:55 | train               |\n",
    "| 2008/04/03 11:32:24 | 2008/04/03 11:46:14 | walk                |\n",
    "| 2008/04/03 11:47:14 | 2008/04/03 11:55:07 | car                 |\n",
    "\n",
    "First, you can regard the label of both taxi and car as driving although we set them with different labels for future usage. Second, a\n",
    "user could label the transportation mode of a light rail as train while others may use subway as the label. Actually, no trajectory\n",
    "can be recorded in an underground subway system since a GPS logger cannot receive any signal there. In Beijing, the light rails\n",
    "and subway systems are seamlessly connected, e.g., line 13 (a light rail) is connected with line 10 and line 2, which are subway\n",
    "systems. Sometimes, a line (like line 5) is comprised of partial subways and partial light rails. So, users may have a variety of\n",
    "understanding in their transportation modes. You can differentiate the real train trajectories (connecting two cities) from the light\n",
    "rail trajectory (generating in a city) according to their distances. Or, just treat them the same.\"\n",
    "\n",
    "----------------------\n",
    "\n",
    "Now that we have a list of the folders in which the mode transportation labels are present and included, we can iterate through these folders and use the labels to filter for the relevant plt files (the ones labeled 'walk'). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75639247-c650-4d0b-92df-dc1d6253c4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 153/153 [04:33<00:00,  1.79s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 76/76 [00:52<00:00,  1.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 32.36it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [01:55<00:00,  1.14it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:00<00:00, 21.49it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00,  6.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:01<00:00,  8.28it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 16.15it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 53.87it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 324/324 [12:43<00:00,  2.36s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:03<00:00,  6.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [01:00<00:00,  1.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 63/63 [00:57<00:00,  1.10it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 128/128 [05:23<00:00,  2.53s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:00<00:00, 14.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:19<00:00,  2.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 182/182 [00:15<00:00, 11.49it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 77/77 [00:28<00:00,  2.72it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 16.11it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:05<00:00,  5.33it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 74/74 [00:38<00:00,  1.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 235/235 [04:35<00:00,  1.17s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 761/761 [24:01<00:00,  1.89s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  8.67it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 13.44it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 104/104 [00:26<00:00,  3.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:10<00:00,  2.05it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 38/38 [00:23<00:00,  1.62it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00,  4.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 18.41it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [00:00<00:00, 28.03it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 30/30 [00:04<00:00,  6.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:06<00:00,  2.85it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:01<00:00, 12.08it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 18.51it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 13.08it/s]\n",
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      " 10%|████████▎                                                                          | 1/10 [00:00<00:02,  3.94it/s]C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      "C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      " 30%|████████████████████████▉                                                          | 3/10 [00:00<00:00,  8.79it/s]C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      "C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      " 50%|█████████████████████████████████████████▌                                         | 5/10 [00:00<00:00, 10.99it/s]C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      "C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [00:00<00:00, 12.17it/s]C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      "C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [00:00<00:00, 13.06it/s]C:\\Users\\16615\\AppData\\Local\\Temp\\ipykernel_38728\\3951165312.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 10.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:01<00:00,  4.94it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 170/170 [01:47<00:00,  1.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  3.56it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:06<00:00,  1.21it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 11/11 [00:00<00:00, 14.17it/s]\n",
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [00:15<00:00,  3.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 240/240 [04:49<00:00,  1.21s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 174/174 [18:46<00:00,  6.47s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00,  8.69it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00,  8.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 19/19 [00:02<00:00,  9.46it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [00:01<00:00,  8.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 68/68 [00:34<00:00,  1.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:11<00:00,  3.74s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 131/131 [00:31<00:00,  4.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 626/626 [1:17:52<00:00,  7.46s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 32/32 [00:04<00:00,  6.50it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 22/22 [00:02<00:00,  9.71it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 1587/1587 [6:55:45<00:00, 15.72s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 392/392 [11:31<00:00,  1.77s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.16it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 10.24it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 163/163 [01:18<00:00,  2.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# iterate through the folders with labels\n",
    "walk_plt_df = pd.DataFrame()\n",
    "\n",
    "for f_id in folders_with_labels:\n",
    "    f_path = os.path.join(geolife_dir, f_id)\n",
    "\n",
    "    # read labels.txt\n",
    "    labels_df = pd.read_csv(f\"{f_path}/labels.txt\", sep=\"\\t\")\n",
    "\n",
    "    # keep only \"walk\" labels\n",
    "    walk_df = labels_df[labels_df['Transportation Mode'] == 'walk']\n",
    "\n",
    "    for _, row in tqdm(walk_df.iterrows(), total=len(walk_df)):\n",
    "        # parse datetimes\n",
    "        start_dt = datetime.strptime(row['Start Time'], '%Y/%m/%d %H:%M:%S')\n",
    "        end_dt   = datetime.strptime(row['End Time'],   '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "        traj_path = os.path.join(f_path, \"Trajectory\")\n",
    "        if not os.path.exists(traj_path):\n",
    "            continue\n",
    "\n",
    "        # loop through all trajectory files\n",
    "        for file in os.listdir(traj_path):\n",
    "            if not file.endswith(\".plt\"):\n",
    "                continue\n",
    "\n",
    "            file_path = os.path.join(traj_path, file)\n",
    "            df = load_plt_file(file_path)\n",
    "\n",
    "            # make timestamp column\n",
    "            df['timestamp'] = pd.to_datetime(df['date_string'] + \" \" + df['time_string'])\n",
    "\n",
    "            # filter points inside the walk interval and make a copy\n",
    "            walk_points = df[(df['timestamp'] >= start_dt) & (df['timestamp'] <= end_dt)].copy()\n",
    "\n",
    "            if not walk_points.empty:\n",
    "                walk_points['user_id'] = f_id\n",
    "                walk_points['file_name'] = file\n",
    "                walk_plt_df = pd.concat([walk_plt_df, walk_points], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "072a1255-8180-4a89-9b47-e436c87b994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial basic data processing\n",
    "walk_plt_df['user_id'] = walk_plt_df['user_id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b168f66-a9f2-4203-bcc7-6a222309e5fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Assigning session IDs: 100%|██████████████████████████████████████████████| 1615614/1615614 [01:08<00:00, 23522.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating an id column for differentiating sessions of traj data\n",
    "session_id_list = []\n",
    "user_session_id_list = []\n",
    "\n",
    "# initialize session counter + tracking variables\n",
    "session_id_count = 1\n",
    "user_session_id_count = 1\n",
    "current_user_id = 10\n",
    "current_file_name = \"20080331160008.plt\"\n",
    "\n",
    "# iterate through each row in plt data\n",
    "for idx, row in tqdm(walk_plt_df.iterrows(), total = len(walk_plt_df), desc = \"Assigning session IDs\"):\n",
    "\n",
    "    user_id = row['user_id']\n",
    "    file_name = row['file_name']\n",
    "    \n",
    "    # check if user_id changes\n",
    "    if user_id != current_user_id:\n",
    "        user_session_id_count = 1\n",
    "        session_id_count += 1\n",
    "        current_user_id = user_id\n",
    "        current_file_name = file_name\n",
    "    # check if file_name changes\n",
    "    elif file_name != current_file_name:\n",
    "        user_session_id_count += 1\n",
    "        session_id_count += 1\n",
    "        current_file_name = file_name\n",
    "    \n",
    "    user_session_id_list.append(user_session_id_count)\n",
    "    session_id_list.append(session_id_count)\n",
    "\n",
    "# add columns to dataframe\n",
    "walk_plt_df['user_session_id'] = user_session_id_list\n",
    "walk_plt_df['session_id'] = session_id_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5275fc5d-4d49-414c-a0e6-484025fc20a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
